{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "import json\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.distributed as dist\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from model_analysis_nets import *\n",
    "from CKA import linear_CKA, kernel_CKA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_mnist = transforms.Compose([transforms.ToTensor(),\n",
    "                                  transforms.Normalize((0.1307,), (0.3081,))])\n",
    "dataset_test = datasets.MNIST('data/mnist/', train=False, download=True, transform=trans_mnist)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "                dataset_test, batch_size=32,\n",
    "                num_workers=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_pth = \"/mnt/sda3/docker_space/Code/TDA-NN/3090/LG-FedAvg/save_attack_ub/cifar10/vgg_iidTrue_num100_C0.8_le2/shard2/pattern11-30--17-48-57/local_attack_save\"\n",
    "normal_pth = \"/mnt/sda3/docker_space/Code/TDA-NN/3090/LG-FedAvg/save_attack_ub/cifar10/vgg_iidTrue_num100_C0.8_le2/shard2/pattern11-30--17-48-57/local_normal_save\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# md1_pth = \"../TDA-NN/3090/LG-FedAvg/save_attack_ub/cifar10/resnet20_iidTrue_num100_C0.8_le2/shard2/pattern12-01--00-32-01/local_attack_save/iter_18_attack_0.pt\"\n",
    "# md2_pth = \"../TDA-NN/3090/LG-FedAvg/save_attack_ub/cifar10/resnet20_iidTrue_num100_C0.8_le2/shard2/pattern12-01--00-32-01/local_normal_save/iter_18_normal_21.pt\"\n",
    "md1_pth = \"../TDA-NN/3090/LG-FedAvg/save_attack_ub/mnist/lenet_iidTrue_num100_C0.8_le2/shard2/pattern11-30--17-49-20/local_attack_save/iter_8_attack_1.pt\"\n",
    "md2_pth = \"../TDA-NN/3090/LG-FedAvg/save_attack_ub/mnist/lenet_iidTrue_num100_C0.8_le2/shard2/pattern11-30--17-49-20/local_normal_save/iter_8_normal_24.pt\"\n",
    "md3_pth = \"../TDA-NN/3090/LG-FedAvg/save_attack_ub/mnist/lenet_iidTrue_num100_C0.8_le2/shard2/pattern11-30--17-49-20/local_attack_save/iter_8_attack_2.pt\"\n",
    "md4_pth = \"../TDA-NN/3090/LG-FedAvg/save_attack_ub/mnist/lenet_iidTrue_num100_C0.8_le2/shard2/pattern11-30--17-49-20/local_normal_save/iter_8_normal_27.pt\"\n",
    "\n",
    "# md1 = torch.load(md1_pth)\n",
    "# md2 = torch.load(md2_pth)\n",
    "# md3 = torch.load(md3_pth)\n",
    "# md4 = torch.load(md4_pth)\n",
    "model1 = LeNet().to(device)\n",
    "model1.load_state_dict(torch.load(md1_pth))\n",
    "model2 = LeNet().to(device)\n",
    "model2.load_state_dict(torch.load(md2_pth))\n",
    "model3 = LeNet().to(device)\n",
    "model3.load_state_dict(torch.load(md3_pth))\n",
    "model4 = LeNet().to(device)\n",
    "model4.load_state_dict(torch.load(md4_pth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet(\n",
      "  (layer1): Sequential(\n",
      "    (0): Conv2d(1, 25, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): BatchNorm2d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Conv2d(25, 50, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=1250, out_features=2048, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): Linear(in_features=1024, out_features=128, bias=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Linear(in_features=128, out_features=10, bias=True)\n",
      "  )\n",
      ") LeNet(\n",
      "  (layer1): Sequential(\n",
      "    (0): Conv2d(1, 25, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): BatchNorm2d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Conv2d(25, 50, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=1250, out_features=2048, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): Linear(in_features=1024, out_features=128, bias=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Linear(in_features=128, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model1,model3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model1.parameters(), lr=0.01, momentum=0.5)\n",
    "\n",
    "for X, Y in test_loader:\n",
    "    X_test = X.to(device)\n",
    "    Y_test = Y.to(device)\n",
    "    break\n",
    "\n",
    "# Forward pass\n",
    "outputs = model1(X_test)\n",
    "\n",
    "# Compute the loss\n",
    "loss = criterion(outputs, Y_test)\n",
    "\n",
    "# Zero the gradients\n",
    "optimizer.zero_grad()\n",
    "\n",
    "# Backward pass\n",
    "loss.backward()\n",
    "\n",
    "# Access the gradients\n",
    "gradients1 = {}\n",
    "for name, param in model1.named_parameters():\n",
    "    gradients1[name] = param.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model2.parameters(), lr=0.01, momentum=0.5)\n",
    "\n",
    "for X, Y in test_loader:\n",
    "    X_test = X.to(device)\n",
    "    Y_test = Y.to(device)\n",
    "    break\n",
    "\n",
    "# Forward pass\n",
    "outputs = model2(X_test)\n",
    "\n",
    "# Compute the loss\n",
    "loss = criterion(outputs, Y_test)\n",
    "\n",
    "# Zero the gradients\n",
    "optimizer.zero_grad()\n",
    "\n",
    "# Backward pass\n",
    "loss.backward()\n",
    "\n",
    "# Access the gradients\n",
    "gradients2 = {}\n",
    "for name, param in model2.named_parameters():\n",
    "    gradients2[name] = param.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model3.parameters(), lr=0.01, momentum=0.5)\n",
    "\n",
    "for X, Y in test_loader:\n",
    "    X_test = X.to(device)\n",
    "    Y_test = Y.to(device)\n",
    "    break\n",
    "\n",
    "# Forward pass\n",
    "outputs = model3(X_test)\n",
    "\n",
    "# Compute the loss\n",
    "loss = criterion(outputs, Y_test)\n",
    "\n",
    "# Zero the gradients\n",
    "optimizer.zero_grad()\n",
    "\n",
    "# Backward pass\n",
    "loss.backward()\n",
    "\n",
    "# Access the gradients\n",
    "gradients3 = {}\n",
    "for name, param in model3.named_parameters():\n",
    "    gradients3[name] = param.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model4.parameters(), lr=0.01, momentum=0.5)\n",
    "\n",
    "for X, Y in test_loader:\n",
    "    X_test = X.to(device)\n",
    "    Y_test = Y.to(device)\n",
    "    break\n",
    "\n",
    "# Forward pass\n",
    "outputs = model4(X_test)\n",
    "\n",
    "# Compute the loss\n",
    "loss = criterion(outputs, Y_test)\n",
    "\n",
    "# Zero the gradients\n",
    "optimizer.zero_grad()\n",
    "\n",
    "# Backward pass\n",
    "loss.backward()\n",
    "\n",
    "# Access the gradients\n",
    "gradients4 = {}\n",
    "for name, param in model4.named_parameters():\n",
    "    gradients4[name] = param.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['layer1.0.weight', 'layer1.0.bias', 'layer1.1.weight', 'layer1.1.bias', 'layer3.0.weight', 'layer3.0.bias', 'layer3.1.weight', 'layer3.1.bias', 'fc.0.weight', 'fc.0.bias', 'fc.2.weight', 'fc.2.bias', 'fc.4.weight', 'fc.4.bias', 'fc.6.weight', 'fc.6.bias'])\n"
     ]
    }
   ],
   "source": [
    "print(gradients1.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "acts1 = gradients1[\"fc.2.weight\"]\n",
    "acts2 = gradients2[\"fc.2.weight\"]\n",
    "acts3 = gradients3[\"fc.2.weight\"]\n",
    "acts4 = gradients4[\"fc.2.weight\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activation shapes torch.Size([1024, 2048]) torch.Size([1024, 2048])\n"
     ]
    }
   ],
   "source": [
    "print(\"activation shapes\", acts1.shape, acts2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "acts1 = acts1.cpu()\n",
    "acts2 = acts2.cpu()\n",
    "acts3 = acts3.cpu()\n",
    "acts4 = acts4.cpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear CKA: 1.0\n",
      "RBF Kernel: 1.0\n"
     ]
    }
   ],
   "source": [
    "print('Linear CKA: {}'.format(linear_CKA(acts1.T, acts2.T)))\n",
    "print('RBF Kernel: {}'.format(kernel_CKA(acts1.T, acts2.T)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear CKA: 0.7925365230940459\n",
      "RBF Kernel: 0.7706235972869823\n"
     ]
    }
   ],
   "source": [
    "print('Linear CKA: {}'.format(linear_CKA(acts1.T, acts3.T)))\n",
    "print('RBF Kernel: {}'.format(kernel_CKA(acts1.T, acts3.T)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear CKA: 0.7449127272374326\n",
      "Linear CKA: 0.7440736646438636\n"
     ]
    }
   ],
   "source": [
    "print('Linear CKA: {}'.format(linear_CKA(acts2.T, acts4.T)))\n",
    "print('Linear CKA: {}'.format(kernel_CKA(acts2.T, acts4.T)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8bff0657a98b8ee576cbe89028f6a544b770fee234379978e147d89ef60d92ed"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
