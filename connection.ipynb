{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "import json\n",
    "import re\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.distributed as dist\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from CKA import linear_CKA, kernel_CKA\n",
    "\n",
    "import numpy as np\n",
    "import sympy\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster, fclusterdata\n",
    "import scipy\n",
    "import networkx as nx\n",
    "import gif\n",
    "\n",
    "from sklearn.manifold import MDS\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import gudhi as gd\n",
    "from ripser import Rips\n",
    "\n",
    "from torchviz import make_dot\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from utils.load import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rounds [32, 34, 22, 24, 26, 28, 30] 7\n",
      "attack [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39] 40\n",
      "normal [40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99] 60\n",
      "560\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "attack_pth = \"./LG-FedAvg/save_attack_ub/cifar10/resnet20_iidTrue_num100_C0.8_le2_DBAFalse/shard2/pattern06-01--20-25-57/local_attack_save/\"\n",
    "normal_pth = \"./LG-FedAvg/save_attack_ub/cifar10/resnet20_iidTrue_num100_C0.8_le2_DBAFalse/shard2/pattern06-01--20-25-57/local_normal_save/\"\n",
    "round_set = []\n",
    "client_set_attack = []\n",
    "client_set_normal = []\n",
    "modelpth_set = []\n",
    "for dirpath, dirnames, filenames in os.walk(attack_pth):\n",
    "    for filename in filenames:\n",
    "        # if int(re.findall(r'-?\\d+', filename)[0]) < round_max and int(re.findall(r'-?\\d+', filename)[1]) < client_max:\n",
    "        modelpth_set.append(os.path.join(dirpath, filename).replace(\"\\\\\",\"/\"))\n",
    "        round_set.append(int(re.findall(r'-?\\d+', filename)[0]))\n",
    "        client_set_attack.append(int(re.findall(r'-?\\d+', filename)[1]))\n",
    "\n",
    "round_set = list(set(round_set))\n",
    "client_set_attack = list(set(client_set_attack))\n",
    "\n",
    "for dirpath, dirnames, filenames in os.walk(normal_pth):\n",
    "    for filename in filenames:\n",
    "        # if int(re.findall(r'-?\\d+', filename)[0]) < round_max and int(re.findall(r'-?\\d+', filename)[1]) < client_max:\n",
    "        modelpth_set.append(os.path.join(dirpath, filename).replace(\"\\\\\",\"/\"))\n",
    "        client_set_normal.append(int(re.findall(r'-?\\d+', filename)[1]))\n",
    "\n",
    "client_set_normal = list(set(client_set_normal))\n",
    "\n",
    "print(\"rounds\", round_set, len(round_set))\n",
    "print(\"attack\", client_set_attack, len(client_set_attack))\n",
    "print(\"normal\", client_set_normal, len(client_set_normal))\n",
    "print(len(modelpth_set))\n",
    "\n",
    "modelpth_dict = {}\n",
    "for idx, r in enumerate(round_set):\n",
    "    current_set_normal = []\n",
    "    current_set_attack = []\n",
    "    for mt in modelpth_set:\n",
    "        # print(mt)\n",
    "        if int(re.findall(r'-?\\d+', mt)[-2]) == r and int(re.findall(r'-?\\d+', mt)[-1]) in client_set_normal:\n",
    "            # print(int(re.findall(r'-?\\d+', mt)[-1]))\n",
    "            current_set_normal.append(mt)\n",
    "        if int(re.findall(r'-?\\d+', mt)[-2]) == r and int(re.findall(r'-?\\d+', mt)[-1]) in client_set_attack:\n",
    "            # print(int(re.findall(r'-?\\d+', mt)[-1]))\n",
    "            current_set_attack.append(mt)\n",
    "        \n",
    "    modelpth_dict[f'{r}_normal'] = current_set_normal\n",
    "    modelpth_dict[f'{r}_attack'] = current_set_attack\n",
    "# print(modelpth_dict)\n",
    "client_max = min(20,len(client_set_attack),len(client_set_normal))\n",
    "corr_set = []\n",
    "\n",
    "modelname = \"\"\n",
    "if \"lenet\" in attack_pth:\n",
    "    modelname = \"lenet\"\n",
    "    weightsize = 50\n",
    "elif \"VGG\" in attack_pth:\n",
    "    modelname = \"vgg\"\n",
    "    weightsize = 64\n",
    "elif \"resnet\" in attack_pth:\n",
    "    modelname = \"resnet\"\n",
    "    weightsize = 64\n",
    "else:\n",
    "    assert 0==1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.datetime.now()\n",
    "formatted_date_time = now.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "writer = SummaryWriter(os.path.join('./log', formatted_date_time))\n",
    "\n",
    "for idround, r in enumerate(round_set):\n",
    "    if idround >= 1:\n",
    "        break\n",
    "    r_modelpth_set = modelpth_dict[f'{r}_normal'][0:client_max] + modelpth_dict[f'{r}_attack'][0:client_max]\n",
    "    # print(len(r_modelpth_set))\n",
    "    r_corr = np.zeros((client_max * 2, client_max * 2, 1))\n",
    "\n",
    "    resultlist = []\n",
    "    modelAndDataloader = initDataset(modelname)\n",
    "    model, test_loader = modelAndDataloader\n",
    "    for idx, modelp1 in enumerate(r_modelpth_set):\n",
    "        model.load_state_dict(torch.load(modelp1))\n",
    "        \n",
    "        for X, Y in test_loader:\n",
    "            X_test = X.to(device)\n",
    "            Y_test = Y.to(device)\n",
    "            # print(Y)\n",
    "            break\n",
    "            \n",
    "        outputs = model(X_test)\n",
    "        # print(outputs)\n",
    "        resultlist.append(outputs.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.zeros(0)\n",
    "print(resultlist[0])\n",
    "a = make_dot(resultlist[10], params=dict(model.named_parameters()))\n",
    "b = make_dot(resultlist[20], params=dict(model.named_parameters()))\n",
    "print(a)\n",
    "print(b)\n",
    "# make_dot(resultlist[1], params=dict(model.named_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "y = model(X_test)\n",
    "print(y.mean())\n",
    "make_dot(y.mean(), params=dict(model.named_parameters()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
